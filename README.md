本仓库包含论文《领域知识迁移对生物实体识别性能和表征的影响研究》的完整代码实现与实验数据。

本研究系统评估了领域知识迁移在生物医学命名实体识别（BioNER）任务中的作用，构建了涵盖 判别式模型（BERT, BioBERT）与 生成式大模型（DeepSeek, Qwen, Kimi）的综合评测框架，并深入探究了全参数微调、LoRA、Prompt Tuning 及零样本推理（Zero-shot）等不同范式的性能边界与表征差异。

📖 项目简介
生物实体识别（NER）是生物医药文本挖掘的基础。通用模型往往难以应对专业术语，而领域知识迁移是解决这一问题的关键。本项目以 玉米基因（Maize Genes） 为研究对象，通过以下多维度的实验揭示了领域迁移的机制与效果：

模型对比：通用预训练（BERT） vs 领域预训练（BioBERT）

范式对比：判别式小模型（Fine-tuning） vs 生成式大模型（Zero-shot LLM）

微调策略：Full Fine-tuning vs LoRA (PEFT) vs Prompt Tuning

深度分析：基于 t-SNE 的表征可视化 & 基于 SVD 的潜在语义主题挖掘

✨ 核心特性
多模型支持：集成了 BERT-base, BioBERT-v1.1 以及主流 LLM API 调用接口（DeepSeek-V3, Qwen2.5/3, Kimi-K2）。

先进微调技术：实现了基于 HuggingFace PEFT 库的 LoRA 和 Prompt Tuning 训练流程。

全流程数据处理：包含从 PubTator/MaizeLitBase 获取数据、BIO 标注转换到模型输入的完整脚本。

深度可视化：提供 t-SNE 降维聚类、实体共现热图、SVD 主题分布图及参数-性能气泡图的绘制代码。



### 📊 表1：不同模型与微调方式的生物实体识别性能对比

| 组别 | Precision | Recall | F1 |
| :--- | :---: | :---: | :---: |
| **BioBERT (FULL)** | 0.8702 | **0.9009** | **0.8853** |
| BERT (FULL) | 0.7822 | <u>0.7795</u> | 0.7809 |
| BioBERT (LoRA) | 0.6660 | 0.7618 | 0.7107 |
| BERT (LoRA) | <u>0.8276</u> | 0.1698 | 0.2818 |
| BioBERT (P-50) | 0.7062 | 0.2948 | 0.4160 |
| BERT (P-50) | **0.9318** | 0.0967 | 0.1752 |
| BioBERT (None) | 0.0104 | 0.0672 | 0.0181 |
| BERT (None) | 0.0126 | 0.0896 | 0.0220 |
| HMM | 0.8513 | 0.7087 | 0.7735 |
| CRF | <u>0.9189</u> | 0.7275 | <u>0.8121</u> |

> **注**：FULL表示全参数微调，LoRA表示低秩适应微调（r=8），P-50表示在50个虚拟Prompt token下进行Prompt Tuning，None表示无微调；Precision为精确率，Recall为召回率，F1为综合性能指标；每列 **加粗** 为最高值，<u>下划线</u> 为次高值。

### 📉 表2：BioBERT使用LoRA在不同秩参数的性能对比

| 模型配置 | Precision | Recall | F1 |
| :--- | :---: | :---: | :---: |
| LoRA (r=4) | *0.6621* | 0.7465 | 0.7018 |
| **LoRA (r=8)** | **0.6660** | 0.7618 | **0.7107** |
| LoRA (r=16) | 0.6612 | 0.7547 | 0.7048 |
| LoRA (r=32) | 0.6588 | **0.7606** | *0.7061* |
| LoRA (r=64) | 0.6568 | *0.7559* | 0.7029 |

> **注**：r表示LoRA的秩参数；Precision为精确率，Recall为召回率，F1为综合性能指标；每列 **加粗** 为最高值，*斜体* 为次高值。

### 📏 表3：BioBERT 在不同 Prompt 长度下的性能

| Prompt长度 | Precision | Recall | F1 |
| :---: | :---: | :---: | :---: |
| 10 | **0.7983** | 0.2193 | 0.3441 |
| 20 | 0.7313 | 0.2535 | 0.3765 |
| 30 | *0.7342* | 0.2606 | 0.3847 |
| 40 | 0.7224 | 0.2854 | 0.4091 |
| 50 | 0.7062 | *0.2948* | *0.4160* |
| 60 | 0.6961 | **0.2972** | **0.4165** |

> **注**：每列 **加粗** 为最大值，*斜体* 为次大值。

### 📏 表4：BERT 在不同 Prompt 长度下的性能

| Prompt长度 | Precision | Recall | F1 |
| :---: | :---: | :---: | :---: |
| 10 | 0.9315 | 0.0802 | 0.1477 |
| 20 | 0.9143 | 0.0755 | 0.1394 |
| 30 | **0.9494** | 0.0884 | 0.1618 |
| 40 | *0.9405* | 0.0932 | 0.1695 |
| 50 | 0.9318 | *0.0967* | *0.1752* |
| 60 | 0.9362 | **0.1038** | **0.1868** |

> **注**：每列 **加粗** 为最大值，*斜体* 为次大值。

### 🤖 表5：不同生成式大模型在零样本设置下的性能对比

| 模型名称 | Precision | Recall | F1 |
| :--- | :---: | :---: | :---: |
| **DeepSeek-V3.2** | 0.5625 | **0.3791** | **0.4529** |
| DeepSeek-V3.1-T | *0.5662* | *0.3550* | *0.4364* |
| Qwen3-N-80B-A3B-I | **0.5837** | 0.3105 | 0.4053 |
| Kimi-K2-I-0905 | 0.5527 | 0.3153 | 0.4015 |
| Qwen2.5-72B-I | 0.5417 | 0.3129 | 0.3966 |

> **注**：所有模型均在零样本（Zero-shot）设置下进行评估；每列 **加粗** 为最高值，*斜体* 为次高值。
> * DeepSeek-V3.2 (*671B*)
> * DeepSeek-V3.1-T: DeepSeek-V3.1-Terminus (*685B*)
> * Qwen3-N-80B-A3B-I: Qwen3-Next-80B-A3B-Instruct (*80B*)
> * Kimi-K2-I-0905: Kimi-K2-Instruct-0905 (*1000B*)
> * Qwen2.5-72B-I: Qwen2.5-72B-Instruct (*72B*)

## 感谢夏老师指导，感谢 MaizeLitBase 提供的数据支持。
