import requests
import json
import os
import time
import random
from typing import List, Optional

# åŸºç¡€URLï¼ˆé¡¹ç›®æ•°æ®æ¥å£çš„æ ¹åœ°å€ï¼‰
BASE_URL = "http://lit-evi.hzau.edu.cn/MaizeAlterome"
# é…ç½®å‚æ•°
SAVE_DIR = "maize_gene_data"  # æ•°æ®ä¿å­˜æ€»ç›®å½•
RETRY_TIMES = 2  # å•ä¸ªåŸºå› ä¸‹è½½å¤±è´¥åçš„é‡è¯•æ¬¡æ•°
DELAY_RANGE = (1, 2)  # æ¯æ¬¡è¯·æ±‚åçš„ä¼‘çœ æ—¶é—´ï¼ˆ1-2ç§’ï¼Œéšæœºé¿å…å›ºå®šé—´éš”ï¼‰
ERROR_LOG_FILE = os.path.join(SAVE_DIR, "download_failures.log")  # å¤±è´¥æ—¥å¿—è·¯å¾„
# Windowsç³»ç»Ÿæ–‡ä»¶åç¦æ­¢çš„éæ³•å­—ç¬¦ï¼ˆç»Ÿä¸€æ›¿æ¢ä¸ºä¸‹åˆ’çº¿ï¼‰
ILLEGAL_CHARS = r'[\\/:*?"<>|]'


def clean_filename(filename: str) -> str:
    """
    æ¸…ç†æ–‡ä»¶åä¸­çš„éæ³•å­—ç¬¦ï¼ˆé€‚é…Windows/Linuxç³»ç»Ÿï¼‰
    :param filename: åŸå§‹æ–‡ä»¶å
    :return: æ¸…ç†åçš„åˆæ³•æ–‡ä»¶å
    """
    import re
    # å°†æ‰€æœ‰éæ³•å­—ç¬¦æ›¿æ¢ä¸ºä¸‹åˆ’çº¿ï¼Œå¤šä¸ªè¿ç»­ä¸‹åˆ’çº¿åˆå¹¶ä¸ºä¸€ä¸ª
    cleaned = re.sub(ILLEGAL_CHARS, '_', filename)
    cleaned = re.sub(r'_+', '_', cleaned)
    # ç§»é™¤æ–‡ä»¶åå¼€å¤´/ç»“å°¾çš„ä¸‹åˆ’çº¿
    cleaned = cleaned.strip('_')
    # é¿å…æ–‡ä»¶åè¿‡é•¿ï¼ˆWindowsæœ€å¤§è·¯å¾„260å­—ç¬¦ï¼Œæ­¤å¤„é™åˆ¶æ–‡ä»¶å80å­—ç¬¦ï¼‰
    if len(cleaned) > 80:
        cleaned = cleaned[:77] + "..."
    return cleaned


def download_all_genes(save_dir: str) -> Optional[List[str]]:
    """
    ä¸‹è½½æ‰€æœ‰åŸºå› åˆ—è¡¨ï¼Œå¹¶æå–å»é‡åçš„åŸºå› å
    :param save_dir: åŸºå› åˆ—è¡¨ä¿å­˜ç›®å½•
    :return: å»é‡åçš„åŸºå› ååˆ—è¡¨ï¼ˆå¦‚["PPDK", "tb1"]ï¼‰ï¼Œå¤±è´¥è¿”å›None
    """
    url = f"{BASE_URL}/all-genes/"
    try:
        print("æ­£åœ¨è·å–æ‰€æœ‰åŸºå› åˆ—è¡¨...")
        response = requests.get(url, timeout=30)
        response.raise_for_status()  # æ£€æŸ¥è¯·æ±‚æ˜¯å¦æˆåŠŸ
        raw_data = response.json()  # åŸå§‹æ•°æ®æ ¼å¼ï¼š[{"gene": "åŸºå› å1"}, {"gene": "åŸºå› å2"}, ...]

        # æå–åŸºå› åå¹¶å»é‡ï¼ˆé¿å…é‡å¤ä¸‹è½½ï¼‰
        gene_list = list({item["gene"].strip() for item in raw_data if "gene" in item and item["gene"].strip()})
        gene_list = [gene for gene in gene_list if gene]  # è¿‡æ»¤ç©ºå­—ç¬¦ä¸²

        # ä¿å­˜åŸå§‹åŸºå› åˆ—è¡¨ï¼ˆå¯é€‰ï¼Œä¾¿äºæ ¸å¯¹ï¼‰
        os.makedirs(save_dir, exist_ok=True)
        raw_save_path = os.path.join(save_dir, "all_genes_raw.json")
        with open(raw_save_path, "w", encoding="utf-8") as f:
            json.dump(raw_data, f, ensure_ascii=False, indent=2)

        print(f"åŸºå› åˆ—è¡¨è·å–æˆåŠŸï¼å…± {len(gene_list)} ä¸ªå”¯ä¸€åŸºå› ")
        print(f"åŸå§‹åŸºå› åˆ—è¡¨å·²ä¿å­˜è‡³ï¼š{raw_save_path}")
        return gene_list

    except requests.exceptions.RequestException as e:
        print(f"è·å–åŸºå› åˆ—è¡¨å¤±è´¥ï¼š{e}")
        return None


def download_single_gene(gene_name: str, save_dir: str) -> bool:
    """
    ä¸‹è½½å•ä¸ªåŸºå› çš„è¯¦ç»†æ•°æ®ï¼ˆå¸¦é‡è¯•æœºåˆ¶ï¼Œä¿®å¤æ–‡ä»¶åç‰¹æ®Šå­—ç¬¦é—®é¢˜ï¼‰
    :param gene_name: ç›®æ ‡åŸºå› å
    :param save_dir: å•ä¸ªåŸºå› æ•°æ®çš„ä¿å­˜ç›®å½•
    :return: ä¸‹è½½æˆåŠŸè¿”å›Trueï¼Œå¤±è´¥è¿”å›False
    """
    url = f"{BASE_URL}/searchbygene/"
    params = {"gene": gene_name}

    # æ¸…ç†åŸºå› åä¸­çš„éæ³•å­—ç¬¦ï¼Œç”Ÿæˆåˆæ³•æ–‡ä»¶å
    cleaned_gene_name = clean_filename(gene_name)
    save_path = os.path.join(save_dir, f"gene_{cleaned_gene_name}.json")

    # è‹¥æ–‡ä»¶å·²å­˜åœ¨ï¼Œè·³è¿‡ä¸‹è½½
    if os.path.exists(save_path):
        print(f"åŸºå›  [{gene_name}] æ•°æ®å·²å­˜åœ¨ï¼Œè·³è¿‡ä¸‹è½½")
        return True

    # é‡è¯•é€»è¾‘
    for retry in range(RETRY_TIMES + 1):
        try:
            response = requests.get(url, params=params, timeout=30)
            response.raise_for_status()
            gene_data = response.json()

            # ä¿å­˜æ•°æ®
            with open(save_path, "w", encoding="utf-8") as f:
                json.dump(gene_data, f, ensure_ascii=False, indent=2)

            # éšæœºä¼‘çœ ï¼Œé¿å…é™æµ
            time.sleep(random.uniform(*DELAY_RANGE))
            print(f"åŸºå›  [{gene_name}] ä¸‹è½½æˆåŠŸï¼ˆä¿å­˜ä¸ºï¼šgene_{cleaned_gene_name}.jsonï¼‰")
            return True

        except requests.exceptions.RequestException as e:
            if retry < RETRY_TIMES:
                print(f"åŸºå›  [{gene_name}] ä¸‹è½½å¤±è´¥ï¼ˆç¬¬{retry + 1}æ¬¡ï¼‰ï¼Œ{e}ï¼Œ10ç§’åé‡è¯•...")
                time.sleep(10)  # å¤±è´¥åå»¶é•¿ä¼‘çœ æ—¶é—´
            else:
                print(f"åŸºå›  [{gene_name}] å¤šæ¬¡ä¸‹è½½å¤±è´¥ï¼š{e}")
                return False


def batch_download_all_genes():
    """
    æ‰¹é‡ä¸‹è½½æ‰€æœ‰åŸºå› çš„è¯¦ç»†æ•°æ®ï¼ˆä¸»å‡½æ•°ï¼‰
    """
    # 1. å…ˆè·å–æ‰€æœ‰å»é‡åŸºå› åˆ—è¡¨
    gene_list = download_all_genes(SAVE_DIR)
    if not gene_list:
        print("æœªè·å–åˆ°åŸºå› åˆ—è¡¨ï¼Œç»ˆæ­¢æ‰¹é‡ä¸‹è½½")
        return

    # 2. åˆ›å»ºåŸºå› è¯¦ç»†æ•°æ®çš„ä¿å­˜å­ç›®å½•
    gene_detail_dir = os.path.join(SAVE_DIR, "gene_details")
    os.makedirs(gene_detail_dir, exist_ok=True)

    # 3. åˆå§‹åŒ–å¤±è´¥æ—¥å¿—
    with open(ERROR_LOG_FILE, "w", encoding="utf-8") as f:
        f.write("ä»¥ä¸‹åŸºå› ä¸‹è½½å¤±è´¥ï¼š\n")

    # 4. éå†ä¸‹è½½æ‰€æœ‰åŸºå› 
    total = len(gene_list)
    failed_genes = []

    for idx, gene in enumerate(gene_list, 1):
        print(f"\nğŸ“Œ æ­£åœ¨ä¸‹è½½ [{idx}/{total}] åŸºå› ï¼š{gene}")
        success = download_single_gene(gene, gene_detail_dir)
        if not success:
            failed_genes.append(gene)
            # è®°å½•å¤±è´¥åŸºå› åˆ°æ—¥å¿—ï¼ˆä¿ç•™åŸå§‹åŸºå› åï¼Œä¾¿äºåç»­æ ¸å¯¹ï¼‰
            with open(ERROR_LOG_FILE, "a", encoding="utf-8") as f:
                f.write(f"{gene}\n")

    # 5. ä¸‹è½½å®Œæˆæ€»ç»“
    print("\n" + "=" * 50)
    print(f"æ‰¹é‡ä¸‹è½½å®Œæˆï¼")
    print(f"æ€»åŸºå› æ•°ï¼š{total}")
    print(f"æˆåŠŸæ•°ï¼š{total - len(failed_genes)}")
    print(f"å¤±è´¥æ•°ï¼š{len(failed_genes)}")
    if failed_genes:
        print(f"å¤±è´¥åŸºå› å·²è®°å½•è‡³ï¼š{ERROR_LOG_FILE}")
    print("=" * 50)

if __name__ == "__main__":
    batch_download_all_genes()